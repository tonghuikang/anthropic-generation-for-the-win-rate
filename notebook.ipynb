{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61cc57a9",
   "metadata": {},
   "source": [
    "# Convert your judge into a generation prompt\n",
    "\n",
    "Given\n",
    "- a certified judge classifier `JUDGE_CLASSIFICATION_PROMPT: str` and optionally `process_response_for_judgement: func[str] -> str`\n",
    "- some input string data samples `INPUT_CONTENTS: tuple[str]`\n",
    "- initial prompt `INITIAL_GENERATION_PROMPT: str`\n",
    "\n",
    "Produce\n",
    "- a prompt with a good winrate (measured by the judge) against other prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffeaa65",
   "metadata": {},
   "source": [
    "## Foreword\n",
    "\n",
    "If you can't verify what is good or what is bad, you can't make good generations.\n",
    "\n",
    "But if you can verify, you should easily be able to make good generations - and this tool helps you write this prompt.\n",
    "\n",
    "\n",
    "#### Inspirations\n",
    "\n",
    "- Cohere prompt tuner https://cohere.com/blog/intro-prompt-tuner\n",
    "- Anthropic workbench https://console.anthropic.com/workbench/\n",
    "- Chatbot Arena leaderboard https://lmarena.ai/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e0aacb",
   "metadata": {},
   "source": [
    "## Example use case presented in this notebook\n",
    "\n",
    "Given a Quora answer, write followup questions to the answer.\n",
    "\n",
    "Great followup questions should be appealing to respond to and answers should be appealing to read.\n",
    "\n",
    "The inputs for this use case\n",
    "- `JUDGE_CLASSIFICATION_PROMPT: str` - prompt that classifies whether one set of output is better than the other\n",
    "- `process_response_for_judgement: func[str] -> str` - how the output is post-processed for judgement\n",
    "- `INPUT_CONTENTS: tuple[str]` - Quora answers\n",
    "- `INITIAL_GENERATION_PROMPT: str` - prompt that generates followup questions\n",
    "\n",
    "Produce\n",
    "- a prompt with a good winrate (measured by the judge) against other prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d93eac0",
   "metadata": {},
   "source": [
    "## Frequently asked questions\n",
    "\n",
    "Why don't you include prompt for `JUDGE_CLASSIFICATION` in the generation prompt?\n",
    "- You can if you want. But the result still needs to perform better according to the judge.\n",
    "- I expect models in the future to be brainstorming responses and then think carefully which is the response is the best. However, doing so will incur extra cost and latency, and we might not want this tradeoff.\n",
    "- The idea of prompt engineering for the generation prompt is to teach the model shortcuts on what good outputs are.\n",
    "\n",
    "Why don't you tune the `JUDGE_CLASSIFICATION` as well?\n",
    "- In this tool we assume that we trust `JUDGE_CLASSIFICATION`.\n",
    "- It is important to get this right. You should tune this, and tune this elsewhere.\n",
    "- In practice we do want to provide feedback to point out where the judge is obviously wrong. I leave this to the roadmap.\n",
    "\n",
    "Why is the `JUDGE_CLASSIFICATION` doing comparison of two generation outputs instead of classifying whether one is good?\n",
    "- For some answers it is easy to generate good followup questions but tricky to generate great followup questions.\n",
    "- In other answers it may be even difficult to generate followup questions that are not outright bad.\n",
    "- I want the judge to be useful in both cases.\n",
    "\n",
    "Why is `judge_classification` is also an input to this tool?\n",
    "- In my prompt, I ask the output to include a rationale along with the text we show to the user.\n",
    "- I don't want the rationale to bias the judgement of text we show to the user.\n",
    "- You might need different post-processing methods for different use-cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79cf20a",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- Print more intermediate results to html\n",
    "- Improve the optimization prompt\n",
    "- Make the optimization prompt write all of system prompt, user prompt and assistant prefill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5054494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cache\n",
    "\n",
    "import anthropic\n",
    "client = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afad7bf3",
   "metadata": {},
   "source": [
    "# Inputs for the tool user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb3864a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df = pd.read_csv(\"content.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36794536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why do AI image generators have so much trouble rendering hands?\\n\\nTong Hui Kang\\nMachine Learning Engineer in Recommendations\\nThe current AI image generators are not rewarded for drawing hands well.\\nThe training input for image models is a huge set of images and their captions. The objective here is to fit a function f(caption) -&gt; image, by minimizing some loss function L(caption, image).\\nL(caption, image) is high when the image is unrelated to the caption, and L(caption, image) is low when the image is very related to the caption. The image generation model is trained to minimize L(caption, image).\\nHowever, L(caption, image) might be high for images with deformities, because L(caption, image) might only measure whether the image is related to the caption.\\nIf you don’t penalize deformities in the training, you can’t generate images free-of-deformities. As of my current understanding, generating images without deformities is still an open question.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>At what point do you consider an LLM to have an ability to plan?\\n\\nTong Hui Kang\\nMachine Learning Engineer in Recommendations\\nConsider the following query and response\\nUser:\\nHow many r are there in strawberry? Check your answer\\nAssistant:\\nThere are 2 'r' letters in the word \"strawberry\".\\nTo check this answer, let's break down the word:\\ns-t-r-a-w-b-e-r-r-y\\nWe can see that there are indeed two instances of the letter 'r' in \"strawberry\":\\n1. The first 'r' comes after 't'\\n2. The second 'r' is the second-to-last letter\\nThis confirms that the answer of 2 'r' letters is correct.\\n\\nhttps://poe.com/s/X6Rkh9wDJ50PSc...\\nThe LLM has planned to BS their justification when they print the number “2”.\\nBad planning is still planning.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    content\n",
       "0  Why do AI image generators have so much trouble rendering hands?\\n\\nTong Hui Kang\\nMachine Learning Engineer in Recommendations\\nThe current AI image generators are not rewarded for drawing hands well.\\nThe training input for image models is a huge set of images and their captions. The objective here is to fit a function f(caption) -> image, by minimizing some loss function L(caption, image).\\nL(caption, image) is high when the image is unrelated to the caption, and L(caption, image) is low when the image is very related to the caption. The image generation model is trained to minimize L(caption, image).\\nHowever, L(caption, image) might be high for images with deformities, because L(caption, image) might only measure whether the image is related to the caption.\\nIf you don’t penalize deformities in the training, you can’t generate images free-of-deformities. As of my current understanding, generating images without deformities is still an open question.\n",
       "1                                                                                                                                                                                                                                    At what point do you consider an LLM to have an ability to plan?\\n\\nTong Hui Kang\\nMachine Learning Engineer in Recommendations\\nConsider the following query and response\\nUser:\\nHow many r are there in strawberry? Check your answer\\nAssistant:\\nThere are 2 'r' letters in the word \"strawberry\".\\nTo check this answer, let's break down the word:\\ns-t-r-a-w-b-e-r-r-y\\nWe can see that there are indeed two instances of the letter 'r' in \"strawberry\":\\n1. The first 'r' comes after 't'\\n2. The second 'r' is the second-to-last letter\\nThis confirms that the answer of 2 'r' letters is correct.\\n\\nhttps://poe.com/s/X6Rkh9wDJ50PSc...\\nThe LLM has planned to BS their justification when they print the number “2”.\\nBad planning is still planning."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "301bbf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_CONTENTS: tuple[str] = tuple(df[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9af58c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_GENERATION_PROMPT = \"\"\"\n",
    "This is a Quora answer. Write 5 followup questions to this answer.\n",
    "\n",
    "Requirements\n",
    "\n",
    "- All phrases in the question should not require any context to be understood.\n",
    "- The questions should not use more words than necessary.\n",
    "- These questions are questions that the author would answer and people would read.\n",
    "\n",
    "\n",
    "Reply in this format\n",
    "\n",
    "<item>\n",
    "<rationale>\n",
    "rationale\n",
    "</rationale>\n",
    "<draft>\n",
    "draft question\n",
    "</draft>\n",
    "<issues>\n",
    "Identify all phrases that could not be understood without context\n",
    "Pay special attention to the following words\n",
    "- other, besides, similar\n",
    "</issues>\n",
    "<draft>\n",
    "<question>\n",
    "fixed question\n",
    "</question>\n",
    "</item>\n",
    "...\n",
    "\n",
    "\n",
    "This is the question and answer.\n",
    "\n",
    "<source_question_and_answer>\n",
    "{input_content}\n",
    "</source_question_and_answer>\n",
    "\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2400fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "JUDGE_CLASSIFICATION_PROMPT = \"\"\"\n",
    "You are given an answer and two sets of followup questions.\n",
    "\n",
    "Determine which set of followup questions is better.\n",
    "\n",
    "Analyze the followup questions for issues.\n",
    "\n",
    "These are the common issues\n",
    "\n",
    "- The question has phrases that could not be understood without reading the source question and answer\n",
    "    - Examples of questions with this issue:\n",
    "        - What functions or teams still regularly use the remaining Castro Street office?\n",
    "            - Reason: \"remaining Castro Street office\" does not make sense without context\n",
    "        - What has been Mike's best performance in an external competitive programming contest?\n",
    "            - Reason: Too vauge who Mike is\n",
    "        - How long has your SoundLink Mini II been working properly since applying this fix?\n",
    "            - Reason: This fix does not make sense without context\n",
    "- The question is using extra words than necessary\n",
    "- The question asks for trivial information that is easily found online\n",
    "\n",
    "Good questions are questions that\n",
    "\n",
    "- The author is likely to answer the question\n",
    "- The readers interested in the source question and answer will also be interested in answers to the followup questions\n",
    "\n",
    "\n",
    "This is the source question and source answer\n",
    "\n",
    "<source_question_and_answer>\n",
    "{input_content}\n",
    "</source_question_and_answer>\n",
    "\n",
    "This is the first set of followup questions\n",
    "\n",
    "{response_one}\n",
    "\n",
    "This is the second set of followup questions\n",
    "\n",
    "{response_two}\n",
    "\n",
    "Reply in this format\n",
    "\n",
    "<Set1>\n",
    "<item>\n",
    "<question>question</question>\n",
    "<issues>issues</issues>\n",
    "</item>\n",
    "...\n",
    "</Set1>\n",
    "\n",
    "<Set2>\n",
    "<item>\n",
    "<question>question</question>\n",
    "<issues>issues</issues>\n",
    "</item>\n",
    "...\n",
    "</Set2>\n",
    "\n",
    "Write some reasoning, end your response with one for the following\n",
    "- Set <label>one</label> is better.\n",
    "- Set <label>two</label> is better.\n",
    "- Both sets <label>tie</label>.\n",
    "\n",
    "Consider a tie if one set of questions is not clearly better than the other.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "954bec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def process_response_for_judgement(response):\n",
    "    pattern = r'<question>(.*?)</question>'\n",
    "    return \"\\n\\n\".join(re.findall(pattern, response, re.DOTALL))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a21d9fd",
   "metadata": {},
   "source": [
    "# Judge classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e326505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume that we trust this prompt\n",
    "\n",
    "def judge_classification(\n",
    "    input_content: str,\n",
    "    response_one: str,\n",
    "    response_two: str,\n",
    ") -> tuple[str, str]:\n",
    "    # return either one, two or tie\n",
    "    \n",
    "    message = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20241022\",\n",
    "        max_tokens=1024,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": JUDGE_CLASSIFICATION_PROMPT.format(\n",
    "                    input_content=input_content,\n",
    "                    response_one=process_response_for_judgement(response_one),\n",
    "                    response_two=process_response_for_judgement(response_two),\n",
    "                )\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    message_text = message.content[0].text\n",
    "    if \"<label>one</label>\" in message_text:\n",
    "        return message_text, \"one\"\n",
    "    if \"<label>two</label>\" in message_text:\n",
    "        return message_text, \"two\"\n",
    "    return message_text, \"tie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "405c66ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_content = \"\"\"\n",
    "Why do AI image generators have so much trouble rendering hands?\n",
    "\n",
    "Tong Hui Kang\n",
    "Machine Learning Engineer in Recommendations\n",
    "The current AI image generators are not rewarded for drawing hands well.\n",
    "The training input for image models is a huge set of images and their captions. The objective here is to fit a function f(caption) -> image, by minimizing some loss function L(caption, image).\n",
    "L(caption, image) is high when the image is unrelated to the caption, and L(caption, image) is low when the image is very related to the caption. The image generation model is trained to minimize L(caption, image).\n",
    "However, L(caption, image) might be high for images with deformities, because L(caption, image) might only measure whether the image is related to the caption.\n",
    "If you don’t penalize deformities in the training, you can’t generate images free-of-deformities. As of my current understanding, generating images without deformities is still an open question.\n",
    "\"\"\".strip()\n",
    "\n",
    "response_one = \"\"\"\n",
    "<question>What are some AI image generation models?</question>\n",
    "\n",
    "<question>Where can I find the training set for the image models?</question>\n",
    "\n",
    "<question>What are some ways to improve the quality of AI-generated images?</question>\n",
    "\n",
    "<question>What is the role of captions in AI image generation?</question>\n",
    "\n",
    "<question>How is L(caption, image) minimized?</question>\n",
    "\"\"\"\n",
    "\n",
    "response_two = \"\"\"\n",
    "<question>How do we reward AI image generators to draw hands correctly?</question>\n",
    "\n",
    "<question>Why are hands particularly challenging compared to other anatomical features?</question>\n",
    "\n",
    "<question>What preprocessing techniques have worked best for curating training datasets that lead to better hand renderings?</question>\n",
    "\n",
    "<question>What specific loss functions have you found most effective for detecting and penalizing anatomical deformities in AI-generated images?</question>\n",
    "\n",
    "<question>How do different AI image generation models (like Stable Diffusion, DALL-E, Midjourney) compare in their ability to render hands?</question>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e584b04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "justification, judgement = judge_classification(\n",
    "    input_content=input_content,\n",
    "    response_one=response_one,\n",
    "    response_two=response_two,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ecb8a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'two'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judgement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eee2a54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Set1>\n",
      "<item>\n",
      "<question>What are some AI image generation models?</question>\n",
      "<issues>Too trivial - easily found online</issues>\n",
      "</item>\n",
      "<item>\n",
      "<question>Where can I find the training set for the image models?</question>\n",
      "<issues>Too trivial - easily found online</issues>\n",
      "</item>\n",
      "<item>\n",
      "<question>What are some ways to improve the quality of AI-generated images?</question>\n",
      "<issues>Too broad and general</issues>\n",
      "</item>\n",
      "<item>\n",
      "<question>What is the role of captions in AI image generation?</question>\n",
      "<issues>Already explained in the answer</issues>\n",
      "</item>\n",
      "<item>\n",
      "<question>How is L(caption, image) minimized?</question>\n",
      "<issues>Too technical without proper context</issues>\n",
      "</item>\n",
      "</Set1>\n",
      "\n",
      "<Set2>\n",
      "<item>\n",
      "<question>How do we reward AI image generators to draw hands correctly?</question>\n",
      "<issues>None - follows directly from answer</issues>\n",
      "</item>\n",
      "<item>\n",
      "<question>Why are hands particularly challenging compared to other anatomical features?</question>\n",
      "<issues>None - relevant extension of original question</issues>\n",
      "</item>\n",
      "<item>\n",
      "<question>What preprocessing techniques have worked best for curating training datasets that lead to better hand renderings?</question>\n",
      "<issues>None - specific and relevant</issues>\n",
      "</item>\n",
      "<item>\n",
      "<question>What specific loss functions have you found most effective for detecting and penalizing anatomical deformities in AI-generated images?</question>\n",
      "<issues>None - directly addresses problem mentioned in answer</issues>\n",
      "</item>\n",
      "<item>\n",
      "<question>How do different AI image generation models compare in their ability to render hands?</question>\n",
      "<issues>None - practical comparison relevant to topic</issues>\n",
      "</item>\n",
      "</Set2>\n",
      "\n",
      "Reasoning:\n",
      "Set 1 consists mainly of questions that are either too basic, easily googleable, or already answered in the original response. They don't build meaningfully on the technical explanation provided.\n",
      "\n",
      "Set 2 asks specific, technical questions that directly address the core problem discussed in the answer (the difficulty in rendering hands). The questions build on the concepts introduced (loss functions, training data, rewards) and seek practical solutions to the problem. They're also more likely to elicit interesting responses from someone knowledgeable in the field.\n",
      "\n",
      "Set <label>two</label> is better.\n"
     ]
    }
   ],
   "source": [
    "print(justification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d77c8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "justification, judgement = judge_classification(\n",
    "    input_content=input_content,\n",
    "    response_one=response_two,  # swapped\n",
    "    response_two=response_one,  # swapped\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87a6a28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judgement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12e2be9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Set1>\n",
      "<item>\n",
      "<question>How do we reward AI image generators to draw hands correctly?</question>\n",
      "<issues>None - directly follows from the answer's discussion of rewards</issues>\n",
      "</item>\n",
      "<item>\n",
      "<question>Why are hands particularly challenging compared to other anatomical features?</question>\n",
      "<issues>None - natural extension of the original question</issues>\n",
      "</item>\n",
      "<item>\n",
      "<question>What preprocessing techniques have worked best for curating training datasets that lead to better hand renderings?</question>\n",
      "<issues>None - technical but relevant follow-up</issues>\n",
      "</item>\n",
      "<item>\n",
      "<question>What specific loss functions have you found most effective for detecting and penalizing anatomical deformities in AI-generated images?</question>\n",
      "<issues>Assumes personal experience which may not exist</issues>\n",
      "</item>\n",
      "<item>\n",
      "<question>How do different AI image generation models compare in their ability to render hands?</question>\n",
      "<issues>Could be considered trivial information findable online</issues>\n",
      "</item>\n",
      "</Set1>\n",
      "\n",
      "<Set2>\n",
      "<item>\n",
      "<question>What are some AI image generation models?</question>\n",
      "<issues>Trivial information easily found online</issues>\n",
      "</item>\n",
      "<item>\n",
      "<question>Where can I find the training set for the image models?</question>\n",
      "<issues>Trivial information easily found online</issues>\n",
      "</item>\n",
      "<item>\n",
      "<question>What are some ways to improve the quality of AI-generated images?</question>\n",
      "<issues>Too broad, not focused on the specific hand rendering problem</issues>\n",
      "</item>\n",
      "<item>\n",
      "<question>What is the role of captions in AI image generation?</question>\n",
      "<issues>Already explained in the answer</issues>\n",
      "</item>\n",
      "<item>\n",
      "<question>How is L(caption, image) minimized?</question>\n",
      "<issues>Already partially explained in the answer</issues>\n",
      "</item>\n",
      "</Set2>\n",
      "\n",
      "Reasoning:\n",
      "Set 1 focuses more specifically on the hand rendering problem and builds upon the technical concepts introduced in the answer. The questions are more targeted and would likely yield interesting insights about the specific challenge of hand rendering.\n",
      "\n",
      "Set 2 contains more general questions about AI image generation, many of which are either already answered in the original response or can be easily found through online searches. The questions don't specifically address the unique challenges of hand rendering.\n",
      "\n",
      "<label>one</label> is better.\n"
     ]
    }
   ],
   "source": [
    "print(justification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5b7b13",
   "metadata": {},
   "source": [
    "# Generation prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9f3a746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation(\n",
    "    generation_prompt: str,\n",
    "    input_content: str,\n",
    ") -> str:\n",
    "    try:\n",
    "        generation_prompt_with_inputs = generation_prompt.format(\n",
    "            input_content=input_content,\n",
    "        )\n",
    "    except:\n",
    "        return \"{input_content} should appear in the prompt\"\n",
    "\n",
    "    message = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20241022\",\n",
    "        max_tokens=1024,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": generation_prompt_with_inputs\n",
    "            },\n",
    "        ],\n",
    "        stop_sequences=[\"</questions>\"],\n",
    "    )\n",
    "    message_text = message.content[0].text\n",
    "    return message_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d80ec16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = generation(INITIAL_GENERATION_PROMPT, input_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9616ac7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let me help create 5 follow-up questions:\n",
      "\n",
      "<item>\n",
      "<rationale>\n",
      "The answer mentions training data and captions, so asking about specific datasets would be relevant.\n",
      "</rationale>\n",
      "<draft>\n",
      "What datasets are commonly used to train AI image generators?\n",
      "</draft>\n",
      "<issues>\n",
      "No context issues found\n",
      "</issues>\n",
      "<question>\n",
      "What datasets are commonly used to train AI image generators?\n",
      "</question>\n",
      "</item>\n",
      "\n",
      "<item>\n",
      "<rationale>\n",
      "The answer discusses loss functions, so exploring alternative loss functions is relevant.\n",
      "</rationale>\n",
      "<draft>\n",
      "What other loss functions could improve hand generation in AI models?\n",
      "</draft>\n",
      "<issues>\n",
      "\"other\" requires context of existing loss functions\n",
      "</issues>\n",
      "<question>\n",
      "Which loss functions could improve hand generation in AI models?\n",
      "</question>\n",
      "</item>\n",
      "\n",
      "<item>\n",
      "<rationale>\n",
      "The answer mentions deformities but doesn't explain why hands specifically are problematic.\n",
      "</rationale>\n",
      "<draft>\n",
      "Why are hands more difficult to generate than other body parts?\n",
      "</draft>\n",
      "<issues>\n",
      "No context issues found\n",
      "</issues>\n",
      "<question>\n",
      "Why are hands more difficult to generate than other body parts?\n",
      "</question>\n",
      "</item>\n",
      "\n",
      "<item>\n",
      "<rationale>\n",
      "The answer suggests that current models don't penalize deformities, so exploring solutions is relevant.\n",
      "</rationale>\n",
      "<draft>\n",
      "How can AI models be trained to recognize and prevent hand deformities?\n",
      "</draft>\n",
      "<issues>\n",
      "No context issues found\n",
      "</issues>\n",
      "<question>\n",
      "How can AI models be trained to recognize and prevent hand deformities?\n",
      "</question>\n",
      "</item>\n",
      "\n",
      "<item>\n",
      "<rationale>\n",
      "The answer implies this is an open problem, so asking about current research is relevant.\n",
      "</rationale>\n",
      "<draft>\n",
      "What are the latest research developments in improving AI hand generation?\n",
      "</draft>\n",
      "<issues>\n",
      "No context issues found\n",
      "</issues>\n",
      "<question>\n",
      "What are the latest research developments in improving AI hand generation?\n",
      "</question>\n",
      "</item>\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fea477c",
   "metadata": {},
   "source": [
    "# Win rate calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65585c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "@cache\n",
    "def calculate_winrate(\n",
    "    input_contents: tuple[str],\n",
    "    generation_prompt_one: str,\n",
    "    generation_prompt_two: str,\n",
    "    filename_suffix: str = \"\",\n",
    "):\n",
    "    one_win = 0\n",
    "    two_win = 0\n",
    "\n",
    "    one_wins_judgements = []\n",
    "    one_loses_judgements = []\n",
    "    two_wins_judgements = []\n",
    "    two_loses_judgements = []\n",
    "    one_tie_judgements = []\n",
    "    two_tie_judgements = []\n",
    "    \n",
    "    def calculate_winrate_single(input_content, index):\n",
    "        response_one = generation(\n",
    "            generation_prompt=generation_prompt_one,\n",
    "            input_content=input_content,\n",
    "        )\n",
    "        response_two = generation(\n",
    "            generation_prompt=generation_prompt_two,\n",
    "            input_content=input_content,\n",
    "        )\n",
    "        flipped = (index%2 == 1)\n",
    "        if not flipped:\n",
    "            justification, judgement = judge_classification(\n",
    "                input_content=input_content,\n",
    "                response_one=response_one,\n",
    "                response_two=response_two,\n",
    "            )\n",
    "        else:\n",
    "            justification, judgement = judge_classification(\n",
    "                input_content=input_content,\n",
    "                response_one=response_two,\n",
    "                response_two=response_one,\n",
    "            )\n",
    "        return response_one, response_two, justification, judgement, flipped\n",
    "        \n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "        results = executor.map(calculate_winrate_single, input_contents, list(range(len(input_contents))))\n",
    "        results = list(results)    \n",
    "    \n",
    "    judgement_unflipped = []\n",
    "    for _, _, justification, judgement, flipped in results:\n",
    "        if not flipped:\n",
    "            if judgement == \"one\":\n",
    "                one_win += 1\n",
    "                judgement_unflipped.append(\"one\")\n",
    "                one_wins_judgements.append(justification)\n",
    "                two_loses_judgements.append(justification)\n",
    "            elif judgement == \"two\":\n",
    "                two_win += 1\n",
    "                judgement_unflipped.append(\"two\")\n",
    "                two_wins_judgements.append(justification)\n",
    "                one_loses_judgements.append(justification)\n",
    "            else:\n",
    "                one_win += 1/2\n",
    "                two_win += 1/2\n",
    "                judgement_unflipped.append(\"tie\")\n",
    "                one_tie_judgements.append(justification)\n",
    "                two_tie_judgements.append(justification)\n",
    "        else:\n",
    "            if judgement == \"two\":\n",
    "                one_win += 1\n",
    "                judgement_unflipped.append(\"one\")\n",
    "                one_wins_judgements.append(justification)\n",
    "                two_loses_judgements.append(justification)\n",
    "            elif judgement == \"one\":\n",
    "                two_win += 1\n",
    "                judgement_unflipped.append(\"two\")\n",
    "                two_wins_judgements.append(justification)\n",
    "                one_loses_judgements.append(justification)\n",
    "            else:\n",
    "                one_win += 1/2\n",
    "                two_win += 1/2\n",
    "                judgement_unflipped.append(\"tie\")\n",
    "                one_tie_judgements.append(justification)\n",
    "                two_tie_judgements.append(justification)\n",
    "    \n",
    "    if filename_suffix:\n",
    "        df_to_display = pd.DataFrame(\n",
    "            {\n",
    "                \"input_content\": [\"\"] + list(input_contents),\n",
    "                \"response_one\": [generation_prompt_one] + [response_one for response_one, _, _, _, _ in results],\n",
    "                \"response_two\": [generation_prompt_two] + [response_two for _, response_two, _, _, _ in results],\n",
    "                \"judgement\": [\"\"] + judgement_unflipped,\n",
    "                \"justification\": [\"\"] + [justification for _, _, justification, _, _ in results],\n",
    "            }\n",
    "        )\n",
    "        display_dataframe(df_to_display, filename_suffix=filename_suffix)\n",
    "        \n",
    "    return (\n",
    "        (\n",
    "            one_win / (one_win + two_win),\n",
    "            one_wins_judgements,\n",
    "            one_tie_judgements,\n",
    "            one_loses_judgements,\n",
    "        ),\n",
    "        (\n",
    "            two_win / (one_win + two_win),\n",
    "            two_wins_judgements,\n",
    "            two_tie_judgements,\n",
    "            two_loses_judgements,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03b9a5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import html\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def display_dataframe(df: pd.DataFrame, filename_suffix=\"\"):\n",
    "    html_prefix = '''\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <style>\n",
    "    table {\n",
    "        border-collapse: collapse;\n",
    "    }\n",
    "    td, th {\n",
    "        border: 1px solid black;\n",
    "        padding: 5px;\n",
    "        vertical-align: top;\n",
    "    }\n",
    "    td {\n",
    "        white-space: pre-wrap;\n",
    "        font-family: monospace;\n",
    "    }\n",
    "    </style>\n",
    "    '''\n",
    "    \n",
    "    # Define a single style function that highlights response_one or response_two based on judgement\n",
    "    def highlight_responses(row):\n",
    "        styles = ['' for _ in row]\n",
    "        if row['judgement'] == 'one':\n",
    "            styles[row.index.get_loc('response_one')] = 'background-color: #90EE90'\n",
    "        elif row['judgement'] == 'two':\n",
    "            styles[row.index.get_loc('response_two')] = 'background-color: #90EE90'\n",
    "        return styles\n",
    "\n",
    "    os.makedirs(\"html_output\", exist_ok=True)\n",
    "    output_table_file_name = f\"html_output/winrate_calculation{filename_suffix}.html\"\n",
    "    \n",
    "    # Replace newline characters and escape HTML\n",
    "    styled_df = df.replace({r'\\n': '__NEWLINE__'}, regex=True).applymap(str).applymap(html.escape).replace({'__NEWLINE__': '<br>'}, regex=True)\n",
    "    \n",
    "    # Apply the style function\n",
    "    styled_df = styled_df.style.apply(highlight_responses, axis=1)\n",
    "    \n",
    "    # Write the styled DataFrame to an HTML file\n",
    "    with open(output_table_file_name, 'w') as f:\n",
    "        f.write(html_prefix + styled_df.render(index=False, escape=False))\n",
    "    \n",
    "    # Create a clickable link to the HTML file\n",
    "    link = f'<a href=\"{output_table_file_name}\" target=\"_blank\">{output_table_file_name}</a>'\n",
    "    display(HTML(link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92be4a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"html_output/winrate_calculation-demo.html\" target=\"_blank\">html_output/winrate_calculation-demo.html</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation_one, evaluation_two = calculate_winrate(\n",
    "    input_contents = INPUT_CONTENTS[:20],\n",
    "    generation_prompt_one = INITIAL_GENERATION_PROMPT,\n",
    "    generation_prompt_two = \"Generate a question and return in <question> and </question>\",\n",
    "    filename_suffix = \"-demo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c4eee7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, [\"<Set1>\\n<item>\\n<question>How do loss functions determine image quality in AI generators?</question>\\n<issues>None - relevant technical question that builds on the answer</issues>\\n</item>\\n<item>\\n<question>What metrics do AI models use to match images with captions?</question>\\n<issues>Somewhat redundant with first question, but still relevant</issues>\\n</item>\\n<item>\\n<question>How can AI models be trained to avoid anatomical deformities?</question>\\n<issues>None - directly addresses\n"
     ]
    }
   ],
   "source": [
    "print(str(evaluation_one)[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efabd546",
   "metadata": {},
   "source": [
    "# Prompt optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9abc71cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_string_template = \"\"\"\n",
    "Winrate: {winrate}\n",
    "Cases where the prompt won: {win_judgements}\n",
    "Cases where the prompt ties: {tie_judgements}\n",
    "Cases where the prompt loses: {lose_judgements}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7dc7f8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_prompt_template = \"\"\"\n",
    "Improve the generation prompt according to the feedback\n",
    "\n",
    "<current_generation_prompt>\n",
    "{generation_prompt}\n",
    "</current_generation_prompt>\n",
    "\n",
    "<feedback>\n",
    "{evaluation_string}\n",
    "</feedback>\n",
    "\n",
    "This is the judging criteria\n",
    "<judging_criteria>\n",
    "{judging_criteria}\n",
    "</judging_criteria>\n",
    "\n",
    "Summarize the changes that you intend to make, and return the new prompt between <prompt> and </prompt>.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c644c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization(\n",
    "    generation_prompt: str,\n",
    "    evaluations: list, \n",
    ") -> str:\n",
    "    evaluation_string = \"\"\n",
    "    for evaluation in evaluations:\n",
    "        winrate, win_judgements, tie_judgements, lose_judgements = evaluation\n",
    "        evaluation_string_single = evaluation_string_template.format(\n",
    "            winrate=winrate,\n",
    "            win_judgements=win_judgements,\n",
    "            tie_judgements=tie_judgements,\n",
    "            lose_judgements=lose_judgements,\n",
    "        )\n",
    "        evaluation_string += evaluation_string_single\n",
    "\n",
    "    optimization_prompt = optimization_prompt_template.format(\n",
    "        generation_prompt=generation_prompt,\n",
    "        evaluation_string=evaluation_string,\n",
    "        judging_criteria=JUDGE_CLASSIFICATION_PROMPT,\n",
    "    )\n",
    "\n",
    "    message = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20241022\",\n",
    "        max_tokens=1024,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": optimization_prompt\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    optimization_response = message.content[0].text\n",
    "    optimized_prompt = extract_from_tags(optimization_response, tag_string=\"prompt\")\n",
    "    \n",
    "    return optimization_response, optimized_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6e77b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_from_tags(text, tag_string=\"prompt\"):\n",
    "    pattern = f'<{tag_string}>(.*?)</{tag_string}>'\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dafa2d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_response, optimized_prompt = optimization(INITIAL_GENERATION_PROMPT, [evaluation_one])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db3da27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the feedback, the prompt consistently wins when it produces questions that:\n",
      "1. Build directly on concepts mentioned in the answer\n",
      "2. Are relevant to the original topic\n",
      "3. Would be useful to readers interested in the original question\n",
      "4. Avoid using contextual phrases\n",
      "5. Don't ask for easily findable information\n",
      "6. Are concise\n",
      "\n",
      "The main changes I'll make:\n",
      "1. Emphasize that questions should build on specific concepts/points mentioned in the answer\n",
      "2. Add explicit requirements about avoiding easily findable information\n",
      "3. Stress the importance of using standalone phrases that don't require context\n",
      "4. Add examples of good and bad questions\n",
      "5. Clarify that questions should interest both the original author and readers\n",
      "\n",
      "Here's the improved prompt:\n",
      "\n",
      "<prompt>\n",
      "This is a Quora answer. Write 5 followup questions to this answer.\n",
      "\n",
      "Requirements:\n",
      "\n",
      "1. Questions must build directly on specific concepts mentioned in the answer\n",
      "2. All phrases must be understandable without reading the source que\n"
     ]
    }
   ],
   "source": [
    "print(optimization_response[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c94a57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Quora answer. Write 5 followup questions to this answer.\n",
      "\n",
      "Requirements:\n",
      "\n",
      "1. Questions must build directly on specific concepts mentioned in the answer\n",
      "2. All phrases must be understandable without reading the source question/answer\n",
      "3. Questions should not use more words than necessary\n",
      "4. Questions should not ask for information that is easily found online\n",
      "5. Questions should interest both the author and readers of the original post\n",
      "\n",
      "Examples of bad questions:\n",
      "- \"What does this solution achieve?\" (requires context)\n",
      "- \"What are the system requirements?\" (easily found online)\n",
      "- \"Besides these approaches, what other methods exist?\" (vague \"these\")\n",
      "\n",
      "Examples of good questions:\n",
      "- \"How do loss functions determine image quality in AI generators?\"\n",
      "- \"What behaviors demonstrate an LLM's ability to plan?\"\n",
      "- \"What solutions are being developed to improve AI hand rendering?\"\n",
      "\n",
      "Reply in this format:\n",
      "\n",
      "<item>\n",
      "<rationale>\n",
      "Explain how this builds on a specific point from the answer\n",
      "</rationale>\n",
      "<draft>\n",
      "draft question\n",
      "</draft>\n",
      "<issues>\n",
      "Identify phrases that:\n",
      "- Require context to understand\n",
      "- Could be more concise\n",
      "- Ask for easily findable information\n",
      "</issues>\n",
      "<question>\n",
      "fixed question\n",
      "</question>\n",
      "</item>\n",
      "...\n",
      "\n",
      "This is the question and answer:\n",
      "\n",
      "<source_question_and_answer>\n",
      "{input_content}\n",
      "</source_question_and_answer>\n"
     ]
    }
   ],
   "source": [
    "print(optimized_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40d7ce0",
   "metadata": {},
   "source": [
    "# Iterative optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62555865",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_prompts = [INITIAL_GENERATION_PROMPT, INITIAL_GENERATION_PROMPT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5988573b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"html_output/winrate_calculation-0-1.html\" target=\"_blank\">html_output/winrate_calculation-0-1.html</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Quora answer. Write 5 followup questions to this answer.\n",
      "\n",
      "Requirements:\n",
      "\n",
      "- All phrases in the question should be understandable without any additional context\n",
      "- Questions should use minimal necessary words\n",
      "- Questions should build naturally from concepts mentioned in the answer\n",
      "- Questions should focus on specific aspects rather than broad topics\n",
      "- Questions should not make assumptions beyond what's stated in the answer\n",
      "- Questions should emphasize practical implementation and real experiences\n",
      "- Questions should balance technical details with user interests\n",
      "- Questions should maintain topic consistency with the original answer\n",
      "- Questions should seek unique insights rather than easily searchable information\n",
      "- Questions should be ones that both the author would likely answer and readers would want to read\n",
      "\n",
      "Reply in this format:\n",
      "\n",
      "<item>\n",
      "<rationale>\n",
      "Why this question follows from the answer and would interest readers\n",
      "</rationale>\n",
      "<draft>\n",
      "draft question\n",
      "</draft>\n",
      "<issues>\n",
      "Identify all phrases that could not be understood without context\n",
      "Pay special attention to:\n",
      "- Assumptions not supported by the answer\n",
      "- Phrases needing context\n",
      "- Topic drift from original focus\n",
      "- Questions answerable through basic research\n",
      "</issues>\n",
      "<question>\n",
      "fixed question\n",
      "</question>\n",
      "</item>\n",
      "...\n",
      "\n",
      "This is the question and answer:\n",
      "\n",
      "<source_question_and_answer>\n",
      "{input_content}\n",
      "</source_question_and_answer>\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"html_output/winrate_calculation-0-2.html\" target=\"_blank\">html_output/winrate_calculation-0-2.html</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"html_output/winrate_calculation-1-2.html\" target=\"_blank\">html_output/winrate_calculation-1-2.html</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Quora answer. Write 5 followup questions to this answer.\n",
      "\n",
      "Requirements:\n",
      "\n",
      "- Questions should focus on personal experience and unique insights rather than easily searchable information\n",
      "- Use minimal necessary words while maintaining clarity\n",
      "- Build naturally from specific details and unique aspects mentioned in the answer\n",
      "- Focus on practical implementation details and real experiences\n",
      "- Questions should interest readers who found the original answer valuable\n",
      "- Ask about specific aspects rather than broad topics\n",
      "- Don't make assumptions beyond what's stated in the answer\n",
      "- Focus on actionable details over general concepts\n",
      "- Target insights that aren't easily found through online searches\n",
      "- Questions should naturally extend from the unique perspective or experience shared in the answer\n",
      "\n",
      "Reply in this format:\n",
      "\n",
      "<item>\n",
      "<rationale>\n",
      "Why this question:\n",
      "- Builds on unique aspects of the answer\n",
      "- Would interest original readers\n",
      "- Asks for insights not easily found elsewhere\n",
      "</rationale>\n",
      "<draft>\n",
      "draft question\n",
      "</draft>\n",
      "<issues>\n",
      "Identify:\n",
      "- Phrases needing context\n",
      "- Unnecessary words\n",
      "- Information easily found online \n",
      "- Assumptions not supported by answer\n",
      "- Topic drift from original focus\n",
      "</issues>\n",
      "<question>\n",
      "fixed question\n",
      "</question>\n",
      "</item>\n",
      "...\n",
      "\n",
      "This is the question and answer:\n",
      "\n",
      "<source_question_and_answer>\n",
      "{input_content}\n",
      "</source_question_and_answer>\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for latest_index in range(1, 3):\n",
    "    generation_prompt_latest = generation_prompts[-1]\n",
    "    evaluations = []\n",
    "    for previous_index, generation_prompt_old in enumerate(generation_prompts[:-1]):\n",
    "        random.seed(f\"{previous_index} {latest_index}\")\n",
    "        input_contents = tuple(random.sample(INPUT_CONTENTS, min(20, len(INPUT_CONTENTS))))\n",
    "        _, evaluation = calculate_winrate(\n",
    "            input_contents,\n",
    "            generation_prompt_old,\n",
    "            generation_prompt_latest,\n",
    "            filename_suffix = f\"-{previous_index}-{latest_index}\",\n",
    "        )\n",
    "        evaluations.append(evaluation)\n",
    "\n",
    "    optimization_response, generation_prompt_new = optimization(generation_prompt_latest, evaluations)\n",
    "    generation_prompts.append(generation_prompt_new)\n",
    "    print(generation_prompt_new)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c471a0d6",
   "metadata": {},
   "source": [
    "# Display winrate table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cf806e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"html_output/winrate_calculation-0-3.html\" target=\"_blank\">html_output/winrate_calculation-0-3.html</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"html_output/winrate_calculation-1-3.html\" target=\"_blank\">html_output/winrate_calculation-1-3.html</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"html_output/winrate_calculation-2-3.html\" target=\"_blank\">html_output/winrate_calculation-2-3.html</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "win_rate_matrix = [[np.nan for _ in generation_prompts] for _ in generation_prompts]\n",
    "\n",
    "for one_idx, prompt_one in enumerate(generation_prompts):\n",
    "    for two_idx, prompt_two in enumerate(generation_prompts[one_idx+1:], start=one_idx+1):\n",
    "        random.seed(f\"{one_idx} {two_idx}\")\n",
    "        input_contents = tuple(random.sample(INPUT_CONTENTS, min(20, len(INPUT_CONTENTS))))\n",
    "        evaluation_one, evaluation_two = calculate_winrate(\n",
    "            input_contents,\n",
    "            prompt_one,\n",
    "            prompt_two,\n",
    "            filename_suffix = f\"-{one_idx}-{two_idx}\",\n",
    "        )\n",
    "        win_rate_one, _, _, _ = evaluation_one\n",
    "        win_rate_two, _, _, _ = evaluation_two\n",
    "        win_rate_matrix[two_idx][one_idx] = win_rate_one\n",
    "        win_rate_matrix[one_idx][two_idx] = win_rate_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cca8721a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[nan, 0.675, 0.8, 0.575],\n",
       " [0.325, nan, 0.85, 0.6],\n",
       " [0.2, 0.15, nan, 0.5],\n",
       " [0.425, 0.4, 0.5, nan]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "win_rate_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32d1d118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1' style='border-collapse: collapse;'><tr><th></th><th>Prompt 0</th><th>Prompt 1</th><th>Prompt 2</th><th>Prompt 3</th></tr><tr><th>Prompt 0</th><td></td><td><a href=\"html_output/winrate_calculation-0-1.html\" target=\"_blank\" style=\"text-decoration: none;\">0.68</a></td><td><a href=\"html_output/winrate_calculation-0-2.html\" target=\"_blank\" style=\"text-decoration: none;\">0.80</a></td><td><a href=\"html_output/winrate_calculation-0-3.html\" target=\"_blank\" style=\"text-decoration: none;\">0.57</a></td></tr><tr><th>Prompt 1</th><td><a href=\"html_output/winrate_calculation-0-1.html\" target=\"_blank\" style=\"text-decoration: none;\">0.33</a></td><td></td><td><a href=\"html_output/winrate_calculation-1-2.html\" target=\"_blank\" style=\"text-decoration: none;\">0.85</a></td><td><a href=\"html_output/winrate_calculation-1-3.html\" target=\"_blank\" style=\"text-decoration: none;\">0.60</a></td></tr><tr><th>Prompt 2</th><td><a href=\"html_output/winrate_calculation-0-2.html\" target=\"_blank\" style=\"text-decoration: none;\">0.20</a></td><td><a href=\"html_output/winrate_calculation-1-2.html\" target=\"_blank\" style=\"text-decoration: none;\">0.15</a></td><td></td><td><a href=\"html_output/winrate_calculation-2-3.html\" target=\"_blank\" style=\"text-decoration: none;\">0.50</a></td></tr><tr><th>Prompt 3</th><td><a href=\"html_output/winrate_calculation-0-3.html\" target=\"_blank\" style=\"text-decoration: none;\">0.42</a></td><td><a href=\"html_output/winrate_calculation-1-3.html\" target=\"_blank\" style=\"text-decoration: none;\">0.40</a></td><td><a href=\"html_output/winrate_calculation-2-3.html\" target=\"_blank\" style=\"text-decoration: none;\">0.50</a></td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "\n",
    "num_prompts = len(generation_prompts)\n",
    "\n",
    "# Start building the HTML table\n",
    "html_table = \"<table border='1' style='border-collapse: collapse;'>\"\n",
    "\n",
    "# Create the header row\n",
    "html_table += \"<tr><th></th>\"\n",
    "for j in range(num_prompts):\n",
    "    html_table += f\"<th>Prompt {j}</th>\"\n",
    "html_table += \"</tr>\"\n",
    "\n",
    "for i in range(num_prompts):\n",
    "    html_table += f\"<tr><th>Prompt {i}</th>\"\n",
    "    for j in range(num_prompts):\n",
    "        if i == j or np.isnan(win_rate_matrix[i][j]):\n",
    "            html_table += \"<td></td>\"  # Empty cell for diagonal or undefined win rates\n",
    "        else:\n",
    "            win_rate = win_rate_matrix[i][j]\n",
    "            cell_html = f'<a href=\"html_output/winrate_calculation-{min(i,j)}-{max(i,j)}.html\" target=\"_blank\" style=\"text-decoration: none;\">{win_rate:.2f}</a>'\n",
    "            html_table += f\"<td>{cell_html}</td>\"\n",
    "    html_table += \"</tr>\"\n",
    "html_table += \"</table>\"\n",
    "\n",
    "display(HTML(html_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1af4883",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "You notice that the prompts keeps getting better, the each prompt is better than the previous prompt, according the the judge we assume we trust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9cfec8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do AI image generators have so much trouble rendering hands?\n",
      "\n",
      "Tong Hui Kang\n",
      "Machine Learning Engineer in Recommendations\n",
      "The current AI image generators are not rewarded for drawing hands well.\n",
      "The training input for image models is a huge set of images and their captions. The objective here is to fit a function f(caption) -> image, by minimizing some loss function L(caption, image).\n",
      "L(caption, image) is high when the image is unrelated to the caption, and L(caption, image) is low when the image is very related to the caption. The image generation model is trained to minimize L(caption, image).\n",
      "However, L(caption, image) might be high for images with deformities, because L(caption, image) might only measure whether the image is related to the caption.\n",
      "If you don’t penalize deformities in the training, you can’t generate images free-of-deformities. As of my current understanding, generating images without deformities is still an open question.\n"
     ]
    }
   ],
   "source": [
    "print(input_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d017c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = generation(generation_prompts[0], input_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0af194d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll create 5 follow-up questions based on this answer.\n",
      "\n",
      "<item>\n",
      "<rationale>\n",
      "This explores the technical aspect of how loss functions work in AI image generation.\n",
      "</rationale>\n",
      "<draft>\n",
      "How does the loss function determine if an image matches its caption?\n",
      "</draft>\n",
      "<issues>\n",
      "No context issues found\n",
      "</issues>\n",
      "<question>\n",
      "How does the loss function determine if an image matches its caption?\n",
      "</question>\n",
      "</item>\n",
      "\n",
      "<item>\n",
      "<rationale>\n",
      "Addresses the fundamental problem mentioned about deformity detection.\n",
      "</rationale>\n",
      "<draft>\n",
      "How can AI detect deformities in generated images?\n",
      "</draft>\n",
      "<issues>\n",
      "No context issues found\n",
      "</issues>\n",
      "<question>\n",
      "How can AI detect deformities in generated images?\n",
      "</question>\n",
      "</item>\n",
      "\n",
      "<item>\n",
      "<rationale>\n",
      "Explores potential solutions to the hand-rendering problem.\n",
      "</rationale>\n",
      "<draft>\n",
      "What training methods could improve AI hand rendering?\n",
      "</draft>\n",
      "<issues>\n",
      "No context issues found\n",
      "</issues>\n",
      "<question>\n",
      "What training methods could improve AI hand rendering?\n",
      "</question>\n",
      "</item>\n",
      "\n",
      "<item>\n",
      "<rationale>\n",
      "Examines why hands are particularly challenging compared to other features.\n",
      "</rationale>\n",
      "<draft>\n",
      "Why are hands harder for AI to generate than other body parts?\n",
      "</draft>\n",
      "<issues>\n",
      "No context issues found\n",
      "</issues>\n",
      "<question>\n",
      "Why are hands harder for AI to generate than other body parts?\n",
      "</question>\n",
      "</item>\n",
      "\n",
      "<item>\n",
      "<rationale>\n",
      "Explores the technical implementation of quality metrics in AI training.\n",
      "</rationale>\n",
      "<draft>\n",
      "How can image quality be measured in AI training?\n",
      "</draft>\n",
      "<issues>\n",
      "No context issues found\n",
      "</issues>\n",
      "<question>\n",
      "How can image quality be measured in AI training?\n",
      "</question>\n",
      "</item>\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e5aac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = generation(generation_prompts[-1], input_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e5abb39",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 5 follow-up questions based on that answer:\n",
      "\n",
      "<item>\n",
      "<rationale>\n",
      "- Explores specific technical implementation details\n",
      "- Builds on the loss function concept mentioned\n",
      "- Seeks practical insight from someone with direct experience\n",
      "</rationale>\n",
      "<draft>\n",
      "What specific loss function modifications have you tried or seen that improve hand rendering quality?\n",
      "</draft>\n",
      "<issues>\n",
      "- Assumes reader has tried modifications\n",
      "- Could be more focused on observed results\n",
      "</issues>\n",
      "<question>\n",
      "Which loss function adjustments have proven most effective for improving hand rendering in your experience?\n",
      "</question>\n",
      "</item>\n",
      "\n",
      "<item>\n",
      "<rationale>\n",
      "- Addresses core problem of deformity detection\n",
      "- Builds on technical explanation\n",
      "- Seeks specific implementation details\n",
      "</rationale>\n",
      "<draft>\n",
      "How could an AI system be trained to specifically recognize and penalize hand deformities?\n",
      "</draft>\n",
      "<issues>\n",
      "- Too theoretical\n",
      "- Needs more focus on practical experience\n",
      "</issues>\n",
      "<question>\n",
      "What methods have you seen used to detect and measure hand deformities in generated images?\n",
      "</question>\n",
      "</item>\n",
      "\n",
      "<item>\n",
      "<rationale>\n",
      "- Explores practical challenges\n",
      "- Builds on training data discussion\n",
      "- Seeks specific technical insights\n",
      "</rationale>\n",
      "<draft>\n",
      "What are the main challenges in creating training datasets that properly capture hand details?\n",
      "</draft>\n",
      "<issues>\n",
      "- Too general\n",
      "- Could be more focused on personal experience\n",
      "</issues>\n",
      "<question>\n",
      "What specific issues with hand representation in training datasets have you encountered?\n",
      "</question>\n",
      "</item>\n",
      "\n",
      "<item>\n",
      "<rationale>\n",
      "- Addresses practical implementation\n",
      "- Builds on caption-image relationship\n",
      "- Seeks specific technical knowledge\n",
      "</rationale>\n",
      "<draft>\n",
      "How do you handle caption-image relationships specifically for hand features?\n",
      "</draft>\n",
      "<issues>\n",
      "- Too broad\n",
      "- Needs more specificity\n",
      "</issues>\n",
      "<question>\n",
      "What caption patterns have you found most effective for generating accurate hand features?\n",
      "</question>\n",
      "</item>\n",
      "\n",
      "<item>\n",
      "<rationale>\n",
      "- Explores real-world solutions\n",
      "- Builds on current limitations\n",
      "- Seeks practical workarounds\n",
      "</rationale>\n",
      "<draft>\n",
      "What current techniques work best for generating hands despite these limitations?\n",
      "</draft>\n",
      "<issues>\n",
      "- Too general\n",
      "- Could be more specific to experience\n",
      "</issues>\n",
      "<question>\n",
      "Which prompt engineering techniques have you found most reliable for generating acceptable hands?\n",
      "</question>\n",
      "</item>\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c062051d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
