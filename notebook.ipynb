{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61cc57a9",
   "metadata": {},
   "source": [
    "# Convert your judge into a generation prompt\n",
    "\n",
    "Given\n",
    "- a certified judge classifier `JUDGE_CLASSIFICATION_PROMPT: str`\n",
    "- some input string data samples `INPUT_CONTENTS: tuple[str]`\n",
    "- initial prompt `INITIAL_GENERATION_PROMPT: str`\n",
    "\n",
    "Produce\n",
    "- a prompt with a good winrate (measured by the judge) against other prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffeaa65",
   "metadata": {},
   "source": [
    "## Foreword\n",
    "\n",
    "If you can't verify what is good or what is bad, you can't make good generations.\n",
    "\n",
    "But if you can verify, you should easily be able to make good generations - and this tool helps you write this prompt.\n",
    "\n",
    "\n",
    "#### Inspirations\n",
    "\n",
    "- Cohere prompt tuner https://cohere.com/blog/intro-prompt-tuner\n",
    "- Anthropic workbench https://console.anthropic.com/workbench/\n",
    "- Chatbot Arena leaderboard https://lmarena.ai/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e0aacb",
   "metadata": {},
   "source": [
    "## Example use case presented in this notebook\n",
    "\n",
    "Given a Quora answer, write followup questions to the answer.\n",
    "\n",
    "Great followup questions should be appealing to respond to and answers should be appealing to read.\n",
    "\n",
    "The inputs for this use case\n",
    "- `JUDGE_CLASSIFICATION_PROMPT: str` - prompt that classifies whether one set of prompts is better than the other\n",
    "- `INPUT_CONTENTS: tuple[str]` - Quora answers\n",
    "- `INITIAL_GENERATION_PROMPT: str` - prompt that generates followup questions\n",
    "\n",
    "Produce\n",
    "- a prompt with a good winrate (measured by the judge) against other prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d93eac0",
   "metadata": {},
   "source": [
    "## Frequently asked questions\n",
    "\n",
    "Why don't you include `JUDGE_CLASSIFICATION_PROMPT` in the generation prompt?\n",
    "- You can if you want. But the result still needs to perform better according to the judge.\n",
    "- I expect models in the future to be brainstorming responses and then think carefully which is the response is the best. However, doing so will incur extra cost and latency, and we might not want this tradeoff.\n",
    "- The idea of prompt engineering for the generation prompt is to teach the model shortcuts on what good outputs are.\n",
    "\n",
    "Why don't you tune the `JUDGE_CLASSIFICATION_PROMPT` as well?\n",
    "- In this tool we assume that we trust `JUDGE_CLASSIFICATION_PROMPT`.\n",
    "- It is important to get this right. You should tune this, and tune this elsewhere.\n",
    "- In practice we do want to provide feedback to point out where the judge is obviously wrong. I leave this to the roadmap.\n",
    "\n",
    "Why is the `JUDGE_CLASSIFICATION_PROMPT` doing comparison of two generation outputs instead of classifying whether one is good?\n",
    "- For some answers it is easy to generate good followup questions but tricky to generate great followup questions.\n",
    "- In other answers it may be even difficult to generate followup questions that are not outright bad.\n",
    "- I want the judge to be useful in both cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79cf20a",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- Print more intermediate results to html\n",
    "- Improve the optimization prompt\n",
    "- Make the optimization prompt write all of system prompt, user prompt and assistant prefill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5054494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cache\n",
    "\n",
    "import anthropic\n",
    "client = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afad7bf3",
   "metadata": {},
   "source": [
    "# Inputs for the tool user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb3864a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df = pd.read_csv(\"content.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36794536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why do AI image generators have so much trouble rendering hands?\\n\\nTong Hui Kang\\nMachine Learning Engineer in Recommendations\\nThe current AI image generators are not rewarded for drawing hands well.\\nThe training input for image models is a huge set of images and their captions. The objective here is to fit a function f(caption) -&gt; image, by minimizing some loss function L(caption, image).\\nL(caption, image) is high when the image is unrelated to the caption, and L(caption, image) is low when the image is very related to the caption. The image generation model is trained to minimize L(caption, image).\\nHowever, L(caption, image) might be high for images with deformities, because L(caption, image) might only measure whether the image is related to the caption.\\nIf you don’t penalize deformities in the training, you can’t generate images free-of-deformities. As of my current understanding, generating images without deformities is still an open question.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>At what point do you consider an LLM to have an ability to plan?\\n\\nTong Hui Kang\\nMachine Learning Engineer in Recommendations\\nConsider the following query and response\\nUser:\\nHow many r are there in strawberry? Check your answer\\nAssistant:\\nThere are 2 'r' letters in the word \"strawberry\".\\nTo check this answer, let's break down the word:\\ns-t-r-a-w-b-e-r-r-y\\nWe can see that there are indeed two instances of the letter 'r' in \"strawberry\":\\n1. The first 'r' comes after 't'\\n2. The second 'r' is the second-to-last letter\\nThis confirms that the answer of 2 'r' letters is correct.\\n\\nhttps://poe.com/s/X6Rkh9wDJ50PSc...\\nThe LLM has planned to BS their justification when they print the number “2”.\\nBad planning is still planning.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    content\n",
       "0  Why do AI image generators have so much trouble rendering hands?\\n\\nTong Hui Kang\\nMachine Learning Engineer in Recommendations\\nThe current AI image generators are not rewarded for drawing hands well.\\nThe training input for image models is a huge set of images and their captions. The objective here is to fit a function f(caption) -> image, by minimizing some loss function L(caption, image).\\nL(caption, image) is high when the image is unrelated to the caption, and L(caption, image) is low when the image is very related to the caption. The image generation model is trained to minimize L(caption, image).\\nHowever, L(caption, image) might be high for images with deformities, because L(caption, image) might only measure whether the image is related to the caption.\\nIf you don’t penalize deformities in the training, you can’t generate images free-of-deformities. As of my current understanding, generating images without deformities is still an open question.\n",
       "1                                                                                                                                                                                                                                    At what point do you consider an LLM to have an ability to plan?\\n\\nTong Hui Kang\\nMachine Learning Engineer in Recommendations\\nConsider the following query and response\\nUser:\\nHow many r are there in strawberry? Check your answer\\nAssistant:\\nThere are 2 'r' letters in the word \"strawberry\".\\nTo check this answer, let's break down the word:\\ns-t-r-a-w-b-e-r-r-y\\nWe can see that there are indeed two instances of the letter 'r' in \"strawberry\":\\n1. The first 'r' comes after 't'\\n2. The second 'r' is the second-to-last letter\\nThis confirms that the answer of 2 'r' letters is correct.\\n\\nhttps://poe.com/s/X6Rkh9wDJ50PSc...\\nThe LLM has planned to BS their justification when they print the number “2”.\\nBad planning is still planning."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "301bbf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_CONTENTS: tuple[str] = tuple(df[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9af58c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_GENERATION_PROMPT = \"\"\"\n",
    "You are given the following source question and a source answer.\n",
    "\n",
    "<source_question_and_answer>\n",
    "{input_content}\n",
    "</source_question_and_answer>\n",
    "\n",
    "Write 5 followup questions to the answer.\n",
    "\n",
    "Reply in this format \n",
    "\n",
    "<questions>\n",
    "\n",
    "<question>\n",
    "question\n",
    "<question>\n",
    "\n",
    "...\n",
    "\n",
    "</questions>\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2400fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "JUDGE_CLASSIFICATION_PROMPT = \"\"\"\n",
    "You are given an answer and two sets of followup questions.\n",
    "\n",
    "Determine which set of followup questions is better.\n",
    "\n",
    "These are required\n",
    "- Each question should appear between <question> and </question>\n",
    "- There should be 5 questions\n",
    "\n",
    "The followup questions are considered bad if they have any of these characteristics\n",
    "- There ambiguous references in the question that cannot be understood without context\n",
    "- The question is using extra words than necessary\n",
    "\n",
    "If both set of questions have neither of the bad characteristics, the better set of followup questions should have these characteristics\n",
    "- Each question should be distinct\n",
    "- The questions ask for knowledge that is not easily found online\n",
    "- The author is likely to answer the questions\n",
    "- People interested in the source question and answer will also be interested in answers to the followup questions\n",
    "\n",
    "This is the source question and source answer\n",
    "<source_question_and_answer>\n",
    "{input_content}\n",
    "</source_question_and_answer>\n",
    "\n",
    "This is the first set of followup questions\n",
    "\n",
    "{response_one}\n",
    "\n",
    "This is the second set of followup questions\n",
    "\n",
    "{response_two}\n",
    "\n",
    "Write some reasoning, end your response with one for the following\n",
    "- Set <label>one</label> is better.\n",
    "- Set <label>two</label> is better.\n",
    "- Both sets <label>tie</label>.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac30939",
   "metadata": {},
   "source": [
    "# Judge classification prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e326505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume that we trust this prompt\n",
    "judge_classification_prompt = JUDGE_CLASSIFICATION_PROMPT\n",
    "\n",
    "def judge_classification(\n",
    "    input_content: str,\n",
    "    response_one: str,\n",
    "    response_two: str,\n",
    ") -> tuple[str, str]:\n",
    "    # return either one, two or tie\n",
    "    \n",
    "    message = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20241022\",\n",
    "        max_tokens=1024,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": judge_classification_prompt.format(\n",
    "                    input_content=input_content,\n",
    "                    response_one=response_one,\n",
    "                    response_two=response_two,\n",
    "                )\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    message_text = message.content[0].text\n",
    "    if \"<label>one</label>\" in message_text:\n",
    "        return message_text, \"one\"\n",
    "    if \"<label>two</label>\" in message_text:\n",
    "        return message_text, \"two\"\n",
    "    return message_text, \"tie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "405c66ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_content = \"\"\"\n",
    "Why do AI image generators have so much trouble rendering hands?\n",
    "\n",
    "Tong Hui Kang\n",
    "Machine Learning Engineer in Recommendations\n",
    "The current AI image generators are not rewarded for drawing hands well.\n",
    "The training input for image models is a huge set of images and their captions. The objective here is to fit a function f(caption) -> image, by minimizing some loss function L(caption, image).\n",
    "L(caption, image) is high when the image is unrelated to the caption, and L(caption, image) is low when the image is very related to the caption. The image generation model is trained to minimize L(caption, image).\n",
    "However, L(caption, image) might be high for images with deformities, because L(caption, image) might only measure whether the image is related to the caption.\n",
    "If you don’t penalize deformities in the training, you can’t generate images free-of-deformities. As of my current understanding, generating images without deformities is still an open question.\n",
    "\"\"\".strip()\n",
    "\n",
    "response_one = \"\"\"\n",
    "<question>What are some AI image generation models?</question>\n",
    "\n",
    "<question>Where can I find the training set for the image models?</question>\n",
    "\n",
    "<question>What are some ways to improve the quality of AI-generated images?</question>\n",
    "\n",
    "<question>What is the role of captions in AI image generation?</question>\n",
    "\n",
    "<question>What techniques have researchers tried so far to address the hand rendering problem?</question>\n",
    "\"\"\"\n",
    "\n",
    "response_two = \"\"\"\n",
    "<question>How do we reward AI image generators to draw hands correction?</question>\n",
    "\n",
    "<question>Why are hands particularly challenging compared to other anatomical features?</question>\n",
    "\n",
    "<question>What preprocessing techniques have worked best for curating training datasets that lead to better hand renderings?</question>\n",
    "\n",
    "<question>What specific loss functions have you found most effective for detecting and penalizing anatomical deformities in AI-generated images?</question>\n",
    "\n",
    "<question>How do different AI image generation models (like Stable Diffusion, DALL-E, Midjourney) compare in their ability to render hands?</question>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e584b04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "justification, judgement = judge_classification(\n",
    "    input_content=input_content,\n",
    "    response_one=response_one,\n",
    "    response_two=response_two,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ecb8a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'two'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judgement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eee2a54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let me analyze both sets:\n",
      "\n",
      "Set One:\n",
      "- Questions are clear and concise\n",
      "- Questions are fairly general and basic\n",
      "- Most answers can be easily found online\n",
      "- Some questions (like \"What are some AI image generation models?\") don't directly build on the specific topic of hand rendering issues\n",
      "- Questions feel less focused on the core problem discussed in the answer\n",
      "\n",
      "Set Two:\n",
      "- Questions are specifically focused on the hand rendering problem\n",
      "- Questions build directly on the concepts mentioned in the answer (loss functions, rewards, training)\n",
      "- Questions require expert knowledge and experience to answer\n",
      "- Questions are likely to generate interesting technical discussions\n",
      "- Each question approaches the problem from a different angle (rewards, anatomical challenges, preprocessing, loss functions, comparative analysis)\n",
      "- The person who answered the original question would likely have valuable insights to share on these topics\n",
      "\n",
      "Set two demonstrates better characteristics because:\n",
      "1. The questions are more distinct from each other\n",
      "2. The answers would require specialized knowledge not easily found through a simple web search\n",
      "3. The questions are highly relevant to anyone interested in the technical challenges of AI image generation\n",
      "4. The questions directly build upon the concepts mentioned in the original answer\n",
      "5. The questions are more likely to generate detailed, technical responses from someone knowledgeable in the field\n",
      "\n",
      "Set <label>two</label> is better.\n"
     ]
    }
   ],
   "source": [
    "print(justification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d77c8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "justification, judgement = judge_classification(\n",
    "    input_content=input_content,\n",
    "    response_one=response_two,  # swapped\n",
    "    response_two=response_one,  # swapped\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87a6a28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judgement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12e2be9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let me analyze both sets:\n",
      "\n",
      "Set One:\n",
      "- Questions are specific and focused on the hand rendering problem\n",
      "- Questions build directly on the core topic\n",
      "- Questions seek expert knowledge that would be valuable to the community\n",
      "- Questions are distinct from each other\n",
      "- Questions are well-formed without ambiguous references\n",
      "- The author, being a Machine Learning Engineer, would likely be able to provide valuable insights on these technical questions\n",
      "\n",
      "Set Two:\n",
      "- Questions are more general and broad\n",
      "- Some questions like \"What are some AI image generation models?\" are easily answerable through a quick internet search\n",
      "- \"Where can I find the training set\" and \"What are some ways to improve quality\" are too broad and not specifically related to the hand rendering problem\n",
      "- Questions don't take full advantage of the author's expertise\n",
      "- While clear, the questions don't maintain strong relevance to the specific problem discussed in the answer\n",
      "\n",
      "Reasoning:\n",
      "1. Set One maintains focus on the specific problem of hand rendering\n",
      "2. Set One asks for technical insights that would be valuable to others working in the field\n",
      "3. Set One's questions build naturally from the answer provided\n",
      "4. Set One takes better advantage of the author's expertise\n",
      "5. Set One's questions would be more interesting to readers who came for the original question\n",
      "6. Set Two's questions are too basic and could mostly be answered through simple research\n",
      "\n",
      "Set <label>one</label> is better.\n"
     ]
    }
   ],
   "source": [
    "print(justification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5b7b13",
   "metadata": {},
   "source": [
    "# Generation prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9f3a746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation(\n",
    "    generation_prompt: str,\n",
    "    input_content: str,\n",
    ") -> str:\n",
    "    try:\n",
    "        generation_prompt_with_inputs = generation_prompt.format(\n",
    "            input_content=input_content,\n",
    "        )\n",
    "    except:\n",
    "        return \"{input_content} should appear in the prompt\"\n",
    "\n",
    "    message = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20241022\",\n",
    "        max_tokens=1024,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": generation_prompt_with_inputs\n",
    "            },\n",
    "        ],\n",
    "        stop_sequences=[\"</questions>\"],\n",
    "    )\n",
    "    message_text = message.content[0].text\n",
    "    return message_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d80ec16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = generation(INITIAL_GENERATION_PROMPT, input_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9616ac7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<questions>\n",
      "\n",
      "<question>\n",
      "How could we modify the loss function L(caption, image) to specifically penalize hand deformities in generated images?\n",
      "</question>\n",
      "\n",
      "<question>\n",
      "Are there specific types of captions or prompts that tend to produce better hand renderings in current AI image generators?\n",
      "</question>\n",
      "\n",
      "<question>\n",
      "Why do hands specifically seem to be more challenging for AI to render compared to other body parts or objects?\n",
      "</question>\n",
      "\n",
      "<question>\n",
      "Could transfer learning from models specifically trained on hand images improve the overall quality of hand generation?\n",
      "</question>\n",
      "\n",
      "<question>\n",
      "How do different AI image generators (like DALL-E, Midjourney, Stable Diffusion) compare in their ability to render hands accurately?\n",
      "</question>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fea477c",
   "metadata": {},
   "source": [
    "# Win rate calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65585c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "@cache\n",
    "def calculate_winrate(\n",
    "    input_contents: tuple[str],\n",
    "    generation_prompt_one: str,\n",
    "    generation_prompt_two: str,\n",
    "    filename_suffix: str = \"\",\n",
    "):\n",
    "    one_win = 0 \n",
    "    two_win = 0\n",
    "\n",
    "    one_wins_judgements = []\n",
    "    one_loses_judgements = []\n",
    "    two_wins_judgements = []\n",
    "    two_loses_judgements = []\n",
    "    one_tie_judgements = []\n",
    "    two_tie_judgements = []\n",
    "    \n",
    "    def calculate_winrate_single(input_content, index):\n",
    "        response_one = generation(\n",
    "            generation_prompt=generation_prompt_one,\n",
    "            input_content=input_content,\n",
    "        )\n",
    "        response_two = generation(\n",
    "            generation_prompt=generation_prompt_two,\n",
    "            input_content=input_content,\n",
    "        )\n",
    "        flipped = (index%2 == 1)\n",
    "        if not flipped:\n",
    "            justification, judgement = judge_classification(\n",
    "                input_content=input_content,\n",
    "                response_one=response_one,\n",
    "                response_two=response_two,\n",
    "            )\n",
    "        else:\n",
    "            justification, judgement = judge_classification(\n",
    "                input_content=input_content,\n",
    "                response_one=response_two,\n",
    "                response_two=response_one,\n",
    "            )\n",
    "        return response_one, response_two, justification, judgement, flipped\n",
    "        \n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "        results = executor.map(calculate_winrate_single, input_contents, list(range(len(input_contents))))\n",
    "        results = list(results)    \n",
    "    \n",
    "    judgement_unflipped = []\n",
    "    for _, _, justification, judgement, flipped in results:\n",
    "        if not flipped:\n",
    "            if judgement == \"one\":\n",
    "                one_win += 1\n",
    "                judgement_unflipped.append(\"one\")\n",
    "                one_wins_judgements.append(justification)\n",
    "                two_loses_judgements.append(justification)\n",
    "            elif judgement == \"two\":\n",
    "                two_win += 1\n",
    "                judgement_unflipped.append(\"two\")\n",
    "                two_wins_judgements.append(justification)\n",
    "                one_loses_judgements.append(justification)\n",
    "            else:\n",
    "                one_win += 1/2\n",
    "                two_win += 1/2\n",
    "                judgement_unflipped.append(\"tie\")\n",
    "                one_tie_judgements.append(justification)\n",
    "                two_tie_judgements.append(justification)\n",
    "        else:\n",
    "            if judgement == \"two\":\n",
    "                one_win += 1\n",
    "                judgement_unflipped.append(\"one\")\n",
    "                one_wins_judgements.append(justification)\n",
    "                two_loses_judgements.append(justification)\n",
    "            elif judgement == \"one\":\n",
    "                two_win += 1\n",
    "                judgement_unflipped.append(\"two\")\n",
    "                two_wins_judgements.append(justification)\n",
    "                one_loses_judgements.append(justification)\n",
    "            else:\n",
    "                one_win += 1/2\n",
    "                two_win += 1/2\n",
    "                judgement_unflipped.append(\"tie\")\n",
    "                one_tie_judgements.append(justification)\n",
    "                two_tie_judgements.append(justification)\n",
    "    \n",
    "    if filename_suffix:\n",
    "        df_to_display = pd.DataFrame(\n",
    "            {\n",
    "                \"input_content\": [\"\"] + list(input_contents),\n",
    "                \"response_one\": [generation_prompt_one] + [response_one for response_one, _, _, _, _ in results],\n",
    "                \"response_two\": [generation_prompt_two] + [response_two for _, response_two, _, _, _ in results],\n",
    "                \"judgement\": [\"\"] + judgement_unflipped,\n",
    "                \"justification\": [\"\"] + [justification for _, _, justification, _, _ in results],\n",
    "            }\n",
    "        )\n",
    "        display_dataframe(df_to_display, filename_suffix=filename_suffix)\n",
    "        \n",
    "    return (\n",
    "        (\n",
    "            one_win / (one_win + two_win),\n",
    "            one_wins_judgements,\n",
    "            one_tie_judgements,\n",
    "            one_loses_judgements,\n",
    "        ),\n",
    "        (\n",
    "            two_win / (one_win + two_win),\n",
    "            two_wins_judgements,\n",
    "            two_tie_judgements,\n",
    "            two_loses_judgements,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03b9a5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import html\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def display_dataframe(df: pd.DataFrame, filename_suffix=\"\"):\n",
    "    html_prefix = '''\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <style>\n",
    "    table {\n",
    "        border-collapse: collapse;\n",
    "    }\n",
    "    td, th {\n",
    "        border: 1px solid black;\n",
    "        padding: 5px;\n",
    "        vertical-align: top;\n",
    "    }\n",
    "    td {\n",
    "        white-space: pre-wrap;\n",
    "        font-family: monospace;\n",
    "    }\n",
    "    </style>\n",
    "    '''\n",
    "    \n",
    "    # Define a single style function that highlights response_one or response_two based on judgement\n",
    "    def highlight_responses(row):\n",
    "        styles = ['' for _ in row]\n",
    "        if row['judgement'] == 'one':\n",
    "            styles[row.index.get_loc('response_one')] = 'background-color: #90EE90'\n",
    "        elif row['judgement'] == 'two':\n",
    "            styles[row.index.get_loc('response_two')] = 'background-color: #90EE90'\n",
    "        return styles\n",
    "\n",
    "    os.makedirs(\"html_output\", exist_ok=True)\n",
    "    output_table_file_name = f\"html_output/winrate_calculation{filename_suffix}.html\"\n",
    "    \n",
    "    # Replace newline characters and escape HTML\n",
    "    styled_df = df.replace({r'\\n': '__NEWLINE__'}, regex=True).applymap(str).applymap(html.escape).replace({'__NEWLINE__': '<br>'}, regex=True)\n",
    "    \n",
    "    # Apply the style function\n",
    "    styled_df = styled_df.style.apply(highlight_responses, axis=1)\n",
    "    \n",
    "    # Write the styled DataFrame to an HTML file\n",
    "    with open(output_table_file_name, 'w') as f:\n",
    "        f.write(html_prefix + styled_df.render(index=False, escape=False))\n",
    "    \n",
    "    # Create a clickable link to the HTML file\n",
    "    link = f'<a href=\"{output_table_file_name}\" target=\"_blank\">{output_table_file_name}</a>'\n",
    "    display(HTML(link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92be4a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"html_output/winrate_calculation-demo.html\" target=\"_blank\">html_output/winrate_calculation-demo.html</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation_one, evaluation_two = calculate_winrate(\n",
    "    input_contents = INPUT_CONTENTS,\n",
    "    generation_prompt_one = INITIAL_GENERATION_PROMPT,\n",
    "    generation_prompt_two = INITIAL_GENERATION_PROMPT,\n",
    "    filename_suffix = \"-demo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c4eee7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5056179775280899, [\"Let me analyze both sets:\\n\\nFirst set:\\n- Questions are clear and specific\\n- No ambiguous references\\n- Questions are concise\\n- Good mix of technical and practical questions\\n- Questions build naturally on the source answer\\n- The question about human artists adds an interesting cross-disciplinary perspective\\n- Asks about specific differences between generators, which is practical\\n\\nSecond set:\\n- Questions are clear and specific\\n- No ambiguous references\\n- Question\n"
     ]
    }
   ],
   "source": [
    "print(str(evaluation_one)[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efabd546",
   "metadata": {},
   "source": [
    "# Prompt optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9abc71cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_string_template = \"\"\"\n",
    "Winrate: {winrate}\n",
    "Cases where the prompt won: {win_judgements}\n",
    "Cases where the prompt ties: {tie_judgements}\n",
    "Cases where the prompt loses: {lose_judgements}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7dc7f8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_prompt_template = \"\"\"\n",
    "Improve the generation prompt according to the feedback\n",
    "\n",
    "<current_generation_prompt>\n",
    "{generation_prompt}\n",
    "</current_generation_prompt>\n",
    "\n",
    "<feedback>\n",
    "{evaluation_string}\n",
    "</feedback>\n",
    "\n",
    "This is the judging criteria\n",
    "<judging_criteria>\n",
    "{judging_criteria}\n",
    "</judging_criteria>\n",
    "\n",
    "Summarize the changes that you intend to make, and return the new prompt between <prompt> and </prompt>.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c644c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization(\n",
    "    generation_prompt: str,\n",
    "    evaluations: list, \n",
    ") -> str:\n",
    "    evaluation_string = \"\"\n",
    "    for evaluation in evaluations:\n",
    "        winrate, win_judgements, tie_judgements, lose_judgements = evaluation\n",
    "        evaluation_string_single = evaluation_string_template.format(\n",
    "            winrate=winrate,\n",
    "            win_judgements=win_judgements,\n",
    "            tie_judgements=tie_judgements,\n",
    "            lose_judgements=lose_judgements,\n",
    "        )\n",
    "        evaluation_string += evaluation_string_single\n",
    "\n",
    "    optimization_prompt = optimization_prompt_template.format(\n",
    "        generation_prompt=generation_prompt,\n",
    "        evaluation_string=evaluation_string,\n",
    "        judging_criteria=JUDGE_CLASSIFICATION_PROMPT,\n",
    "    )\n",
    "\n",
    "    message = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20241022\",\n",
    "        max_tokens=1024,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": optimization_prompt\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    optimization_response = message.content[0].text\n",
    "    optimized_prompt = extract_from_tags(optimization_response, tag_string=\"prompt\")\n",
    "    \n",
    "    return optimization_response, optimized_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6e77b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_from_tags(text, tag_string=\"prompt\"):\n",
    "    pattern = f'<{tag_string}>(.*?)</{tag_string}>'\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dafa2d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_response, optimized_prompt = optimization(INITIAL_GENERATION_PROMPT, [evaluation_one])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db3da27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the feedback analysis, here are the key improvements needed for the generation prompt:\n",
      "\n",
      "1. Better specify quality criteria in the prompt:\n",
      "- Questions should be distinct from each other\n",
      "- Questions should ask for knowledge not easily found through online searches\n",
      "- Questions should be likely to get responses from the author based on their demonstrated expertise\n",
      "- Questions should maintain relevance to anyone interested in the original topic\n",
      "\n",
      "2. Explicitly state avoidance criteria:\n",
      "- No ambiguous references that require additional context\n",
      "- No unnecessary words or verbose phrasing\n",
      "\n",
      "3. Add guidance for question progression and flow:\n",
      "- Questions should build naturally from the source material\n",
      "- Questions should follow a logical progression\n",
      "- Questions should maintain connection to key points in the original answer\n",
      "\n",
      "4. Emphasize balance between:\n",
      "- Technical and practical aspects\n",
      "- Specific details and broader implications\n",
      "- Personal experience and general knowledge\n",
      "\n",
      "Here's the impr\n"
     ]
    }
   ],
   "source": [
    "print(optimization_response[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c94a57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are given the following source question and a source answer.\n",
      "\n",
      "<source_question_and_answer>\n",
      "{input_content}\n",
      "</source_question_and_answer>\n",
      "\n",
      "Write 5 followup questions to the answer. The questions should:\n",
      "- Be distinct from each other without overlap\n",
      "- Ask for knowledge that isn't easily found through online searches\n",
      "- Be likely to get responses based on the author's demonstrated expertise\n",
      "- Be relevant to people interested in the original topic\n",
      "- Build naturally from the source material\n",
      "- Follow a logical progression\n",
      "- Maintain clear connection to key points in the original answer\n",
      "- Balance technical and practical aspects where appropriate\n",
      "\n",
      "Avoid:\n",
      "- Ambiguous references that require additional context\n",
      "- Unnecessary words or verbose phrasing\n",
      "\n",
      "Reply in this format:\n",
      "\n",
      "<questions>\n",
      "\n",
      "<question>\n",
      "[Your question here]\n",
      "</question>\n",
      "\n",
      "[Repeat for all 5 questions]\n",
      "\n",
      "</questions>\n"
     ]
    }
   ],
   "source": [
    "print(optimized_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40d7ce0",
   "metadata": {},
   "source": [
    "# Iterative optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62555865",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_prompts = [INITIAL_GENERATION_PROMPT, INITIAL_GENERATION_PROMPT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5988573b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"html_output/winrate_calculation-0-1.html\" target=\"_blank\">html_output/winrate_calculation-0-1.html</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are given the following source question and a source answer.\n",
      "\n",
      "<source_question_and_answer>\n",
      "{input_content}\n",
      "</source_question_and_answer>\n",
      "\n",
      "Write 5 followup questions that:\n",
      "- Flow naturally from the source answer\n",
      "- Are direct and concise (avoid phrases like \"Can you elaborate\" or \"Could you provide\")\n",
      "- Focus on distinct aspects with no overlap between questions\n",
      "- Ask for insights not easily found through online searches\n",
      "- Can be answered based on the author's demonstrated knowledge\n",
      "- Balance technical and practical aspects when applicable\n",
      "- Provide value to people interested in the original topic\n",
      "\n",
      "Reply in this format:\n",
      "\n",
      "<questions>\n",
      "\n",
      "<question>\n",
      "question\n",
      "</question>\n",
      "\n",
      "...\n",
      "\n",
      "</questions>\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"html_output/winrate_calculation-0-2.html\" target=\"_blank\">html_output/winrate_calculation-0-2.html</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"html_output/winrate_calculation-1-2.html\" target=\"_blank\">html_output/winrate_calculation-1-2.html</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are given the following source question and a source answer.\n",
      "\n",
      "<source_question_and_answer>\n",
      "{input_content}\n",
      "</source_question_and_answer>\n",
      "\n",
      "Write 5 followup questions that:\n",
      "- Flow naturally from specific points in the source answer\n",
      "- Use simple, clear language without unnecessary words\n",
      "- Focus on practical rather than theoretical aspects\n",
      "- Ask about specific experiences and observations\n",
      "- Target topics where the author has demonstrated knowledge\n",
      "- Ask for insights not easily found through online searches\n",
      "- Would interest readers of the original answer\n",
      "- Are distinct with no overlap between questions\n",
      "\n",
      "Reply in this format:\n",
      "\n",
      "<questions>\n",
      "\n",
      "<question>\n",
      "question\n",
      "</question>\n",
      "\n",
      "...\n",
      "\n",
      "</questions>\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"html_output/winrate_calculation-0-3.html\" target=\"_blank\">html_output/winrate_calculation-0-3.html</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"html_output/winrate_calculation-1-3.html\" target=\"_blank\">html_output/winrate_calculation-1-3.html</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"html_output/winrate_calculation-2-3.html\" target=\"_blank\">html_output/winrate_calculation-2-3.html</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are given the following source question and a source answer.\n",
      "\n",
      "<source_question_and_answer>\n",
      "{input_content}\n",
      "</source_question_and_answer>\n",
      "\n",
      "Write 5 followup questions that:\n",
      "- Build directly from specific points mentioned in the source answer\n",
      "- Ask for personal experiences, examples and observations where appropriate\n",
      "- Focus on practical implementation rather than theory\n",
      "- Seek insights not easily found through online searches\n",
      "- Target topics where the author has demonstrated knowledge/experience\n",
      "- Use concise language while maintaining clarity\n",
      "- Are distinct with no overlap between questions\n",
      "- Avoid assumptions not supported by the source material\n",
      "\n",
      "Reply in this format:\n",
      "\n",
      "<questions>\n",
      "\n",
      "<question>\n",
      "question\n",
      "</question>\n",
      "\n",
      "...\n",
      "\n",
      "</questions>\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for latest_index in range(1, 4):\n",
    "    generation_prompt_latest = generation_prompts[-1]\n",
    "    evaluations = []\n",
    "    for previous_index, generation_prompt_old in enumerate(generation_prompts[:-1]):\n",
    "        random.seed(f\"{previous_index} {latest_index}\")\n",
    "        input_contents = tuple(random.sample(INPUT_CONTENTS, min(20, len(INPUT_CONTENTS))))\n",
    "        _, evaluation = calculate_winrate(\n",
    "            input_contents,\n",
    "            generation_prompt_old,\n",
    "            generation_prompt_latest,\n",
    "            filename_suffix = f\"-{previous_index}-{latest_index}\",\n",
    "        )\n",
    "        evaluations.append(evaluation)\n",
    "\n",
    "    optimization_response, generation_prompt_new = optimization(generation_prompt_latest, evaluations)\n",
    "    generation_prompts.append(generation_prompt_new)\n",
    "    print(generation_prompt_new)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c471a0d6",
   "metadata": {},
   "source": [
    "# Display winrate table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8cf806e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"html_output/winrate_calculation-0-4.html\" target=\"_blank\">html_output/winrate_calculation-0-4.html</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"html_output/winrate_calculation-1-4.html\" target=\"_blank\">html_output/winrate_calculation-1-4.html</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"html_output/winrate_calculation-2-4.html\" target=\"_blank\">html_output/winrate_calculation-2-4.html</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"html_output/winrate_calculation-3-4.html\" target=\"_blank\">html_output/winrate_calculation-3-4.html</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "win_rate_matrix = [[np.nan for _ in generation_prompts] for _ in generation_prompts]\n",
    "\n",
    "for one_idx, prompt_one in enumerate(generation_prompts):\n",
    "    for two_idx, prompt_two in enumerate(generation_prompts[one_idx+1:], start=one_idx+1):\n",
    "        random.seed(f\"{one_idx} {two_idx}\")\n",
    "        input_contents = tuple(random.sample(INPUT_CONTENTS, min(20, len(INPUT_CONTENTS))))\n",
    "        evaluation_one, evaluation_two = calculate_winrate(\n",
    "            input_contents,\n",
    "            prompt_one,\n",
    "            prompt_two,\n",
    "            filename_suffix = f\"-{one_idx}-{two_idx}\",\n",
    "        )\n",
    "        win_rate_one, _, _, _ = evaluation_one\n",
    "        win_rate_two, _, _, _ = evaluation_two\n",
    "        win_rate_matrix[one_idx][two_idx] = win_rate_one\n",
    "        win_rate_matrix[two_idx][one_idx] = win_rate_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cca8721a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[nan, 0.45, 0.45, 0.2, 0.425],\n",
       " [0.55, nan, 0.25, 0.25, 0.4],\n",
       " [0.55, 0.75, nan, 0.3, 0.4],\n",
       " [0.8, 0.75, 0.7, nan, 0.5],\n",
       " [0.575, 0.6, 0.6, 0.5, nan]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "win_rate_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32d1d118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1' style='border-collapse: collapse;'><tr><th></th><th>Prompt 0</th><th>Prompt 1</th><th>Prompt 2</th><th>Prompt 3</th><th>Prompt 4</th></tr><tr><th>Prompt 0</th><td></td><td><a href=\"html_output/winrate_calculation-0-1.html\" target=\"_blank\" style=\"text-decoration: none;\">0.45</a></td><td><a href=\"html_output/winrate_calculation-0-2.html\" target=\"_blank\" style=\"text-decoration: none;\">0.45</a></td><td><a href=\"html_output/winrate_calculation-0-3.html\" target=\"_blank\" style=\"text-decoration: none;\">0.20</a></td><td><a href=\"html_output/winrate_calculation-0-4.html\" target=\"_blank\" style=\"text-decoration: none;\">0.42</a></td></tr><tr><th>Prompt 1</th><td><a href=\"html_output/winrate_calculation-0-1.html\" target=\"_blank\" style=\"text-decoration: none;\">0.55</a></td><td></td><td><a href=\"html_output/winrate_calculation-1-2.html\" target=\"_blank\" style=\"text-decoration: none;\">0.25</a></td><td><a href=\"html_output/winrate_calculation-1-3.html\" target=\"_blank\" style=\"text-decoration: none;\">0.25</a></td><td><a href=\"html_output/winrate_calculation-1-4.html\" target=\"_blank\" style=\"text-decoration: none;\">0.40</a></td></tr><tr><th>Prompt 2</th><td><a href=\"html_output/winrate_calculation-0-2.html\" target=\"_blank\" style=\"text-decoration: none;\">0.55</a></td><td><a href=\"html_output/winrate_calculation-1-2.html\" target=\"_blank\" style=\"text-decoration: none;\">0.75</a></td><td></td><td><a href=\"html_output/winrate_calculation-2-3.html\" target=\"_blank\" style=\"text-decoration: none;\">0.30</a></td><td><a href=\"html_output/winrate_calculation-2-4.html\" target=\"_blank\" style=\"text-decoration: none;\">0.40</a></td></tr><tr><th>Prompt 3</th><td><a href=\"html_output/winrate_calculation-0-3.html\" target=\"_blank\" style=\"text-decoration: none;\">0.80</a></td><td><a href=\"html_output/winrate_calculation-1-3.html\" target=\"_blank\" style=\"text-decoration: none;\">0.75</a></td><td><a href=\"html_output/winrate_calculation-2-3.html\" target=\"_blank\" style=\"text-decoration: none;\">0.70</a></td><td></td><td><a href=\"html_output/winrate_calculation-3-4.html\" target=\"_blank\" style=\"text-decoration: none;\">0.50</a></td></tr><tr><th>Prompt 4</th><td><a href=\"html_output/winrate_calculation-0-4.html\" target=\"_blank\" style=\"text-decoration: none;\">0.57</a></td><td><a href=\"html_output/winrate_calculation-1-4.html\" target=\"_blank\" style=\"text-decoration: none;\">0.60</a></td><td><a href=\"html_output/winrate_calculation-2-4.html\" target=\"_blank\" style=\"text-decoration: none;\">0.60</a></td><td><a href=\"html_output/winrate_calculation-3-4.html\" target=\"_blank\" style=\"text-decoration: none;\">0.50</a></td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "\n",
    "num_prompts = len(generation_prompts)\n",
    "\n",
    "# Start building the HTML table\n",
    "html_table = \"<table border='1' style='border-collapse: collapse;'>\"\n",
    "\n",
    "# Create the header row\n",
    "html_table += \"<tr><th></th>\"\n",
    "for j in range(num_prompts):\n",
    "    html_table += f\"<th>Prompt {j}</th>\"\n",
    "html_table += \"</tr>\"\n",
    "\n",
    "for i in range(num_prompts):\n",
    "    html_table += f\"<tr><th>Prompt {i}</th>\"\n",
    "    for j in range(num_prompts):\n",
    "        if i == j or np.isnan(win_rate_matrix[i][j]):\n",
    "            html_table += \"<td></td>\"  # Empty cell for diagonal or undefined win rates\n",
    "        else:\n",
    "            win_rate = win_rate_matrix[i][j]\n",
    "            cell_html = f'<a href=\"html_output/winrate_calculation-{min(i,j)}-{max(i,j)}.html\" target=\"_blank\" style=\"text-decoration: none;\">{win_rate:.2f}</a>'\n",
    "            html_table += f\"<td>{cell_html}</td>\"\n",
    "    html_table += \"</tr>\"\n",
    "html_table += \"</table>\"\n",
    "\n",
    "display(HTML(html_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1af4883",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "You notice that the prompts keeps getting better, the each prompt is better than the previous prompt, according the the judge we assume we trust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9cfec8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do AI image generators have so much trouble rendering hands?\n",
      "\n",
      "Tong Hui Kang\n",
      "Machine Learning Engineer in Recommendations\n",
      "The current AI image generators are not rewarded for drawing hands well.\n",
      "The training input for image models is a huge set of images and their captions. The objective here is to fit a function f(caption) -> image, by minimizing some loss function L(caption, image).\n",
      "L(caption, image) is high when the image is unrelated to the caption, and L(caption, image) is low when the image is very related to the caption. The image generation model is trained to minimize L(caption, image).\n",
      "However, L(caption, image) might be high for images with deformities, because L(caption, image) might only measure whether the image is related to the caption.\n",
      "If you don’t penalize deformities in the training, you can’t generate images free-of-deformities. As of my current understanding, generating images without deformities is still an open question.\n"
     ]
    }
   ],
   "source": [
    "print(input_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d017c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = generation(generation_prompts[0], input_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0af194d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<questions>\n",
      "\n",
      "<question>\n",
      "How could we modify the loss function L(caption, image) to specifically penalize hand deformities in generated images?\n",
      "</question>\n",
      "\n",
      "<question>\n",
      "Are there any specific architectural changes in AI models that could help improve the rendering of hands, or is it purely a training data/loss function issue?\n",
      "</question>\n",
      "\n",
      "<question>\n",
      "Do other complex anatomical features (like faces or feet) face similar rendering challenges, or is this problem unique to hands?\n",
      "</question>\n",
      "\n",
      "<question>\n",
      "Could incorporating 3D anatomical models or skeletal structure information into the training process help improve hand rendering?\n",
      "</question>\n",
      "\n",
      "<question>\n",
      "How do human artists learn to draw hands correctly, and could these principles be somehow incorporated into AI training methods?\n",
      "</question>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e5aac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = generation(generation_prompts[-1], input_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e5abb39",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<questions>\n",
      "\n",
      "<question>\n",
      "Could you share specific examples of loss functions you've implemented or encountered that effectively measure image-caption relationships while avoiding deformity issues?\n",
      "</question>\n",
      "\n",
      "<question>\n",
      "In your experience working with image generation models, what modifications to training objectives have shown the most promise in reducing hand deformities specifically?\n",
      "</question>\n",
      "\n",
      "<question>\n",
      "How do you practically evaluate and measure deformities in generated images during the training process, beyond just caption relevance?\n",
      "</question>\n",
      "\n",
      "<question>\n",
      "Based on your machine learning background, what approaches for penalizing anatomical irregularities have you seen attempted in real-world implementations?\n",
      "</question>\n",
      "\n",
      "<question>\n",
      "When working with recommendation systems, have you found any parallels between detecting poor quality content and identifying deformities in generated images that could be applied here?\n",
      "</question>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c062051d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
